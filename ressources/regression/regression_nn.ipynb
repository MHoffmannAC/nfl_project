{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "from keys import aiven_pwd \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "sql_engine = create_engine(f\"mysql+pymysql://avnadmin:{aiven_pwd}@mysql-nfl-mhoffmann-nfl.b.aivencloud.com:10448/nfl\", pool_size=20, max_overflow=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = \"(2025, 2024, 2023)\"\n",
    "#years = \"(2024)\"\n",
    "query = f\"\"\" \n",
    "SELECT\n",
    "    #p.play_id,\n",
    "    #p.game_id,\n",
    "    #p.sequenceNumber,\n",
    "    p.homeScore,\n",
    "    p.awayScore,\n",
    "    p.quarter,\n",
    "    TIME_TO_SEC(p.clock) AS clock_seconds,\n",
    "    p.offenseAtHome,\n",
    "    p.down,\n",
    "    p.distance,\n",
    "    p.yardsToEndzone,\n",
    "    p.playtype_id,\n",
    "    g.season,\n",
    "    g.game_type,\n",
    "    g.week,\n",
    "    g.standing_home_overall_win,\n",
    "    g.standing_home_home_win,\n",
    "    g.standing_home_road_win,\n",
    "    g.standing_home_overall_loss,\n",
    "    g.standing_home_home_loss,\n",
    "    g.standing_home_road_loss,\n",
    "    g.standing_away_overall_win,\n",
    "    g.standing_away_home_win,\n",
    "    g.standing_away_road_win,\n",
    "    g.standing_away_overall_loss,\n",
    "    g.standing_away_home_loss,\n",
    "    g.standing_away_road_loss,\n",
    "    t1.abbreviation AS homeAbr,\n",
    "    t2.abbreviation AS awayAbr,\n",
    "    (p.homeScore - p.awayScore) AS scoreDiff,\n",
    "    (TIME_TO_SEC(p.clock) + (4 - p.quarter) * 15 * 60) AS totalTimeLeft,\n",
    "    pr.homeWinPercentage,\n",
    "    pr.awayWinPercentage,\n",
    "    pr.tiePercentage\n",
    "FROM\n",
    "    nfl.plays p\n",
    "LEFT JOIN nfl.games g ON p.game_id = g.game_id\n",
    "LEFT JOIN nfl.probabilities pr ON p.game_id = pr.game_id AND p.sequenceNumber = pr.sequenceNumber\n",
    "LEFT JOIN nfl.teams t1 ON g.home_team_id = t1.team_id\n",
    "LEFT JOIN nfl.teams t2 ON g.away_team_id = t2.team_id\n",
    "WHERE g.season IN {years}\n",
    "\"\"\"\n",
    "\n",
    "#WHERE\n",
    "#    g.season<2024 OR (g.season=2024 AND g.game_type='regular-season' AND g.week<=10);\n",
    "\n",
    "sql_data = pd.DataFrame(sql_engine.connect().execute(text(query)).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = sql_data.copy()\n",
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playtype_mapping = {\n",
    "    2: None, \n",
    "    3: 'Pass', \n",
    "    5: 'Rush', \n",
    "    6: 'Pass', \n",
    "    7: None, \n",
    "    8: None, \n",
    "    9: None, \n",
    "    12: None, # 'Kickoff',\n",
    "    15: None, # '2P-Pass',\n",
    "    16:  None, # '2P-Rush',\n",
    "    17: 'Punt',\n",
    "    18: 'FG',\n",
    "    20: None,\n",
    "    21: None,\n",
    "    24: 'Pass',\n",
    "    26: 'Pass',\n",
    "    29: None,\n",
    "    30: 'Punt',\n",
    "    32: None, # 'Kickoff',\n",
    "    34: 'Punt',\n",
    "    36: 'Pass',\n",
    "    37: 'Punt',\n",
    "    38: 'FG',\n",
    "    39: None,\n",
    "    40: 'FG',\n",
    "    41: 'FG',\n",
    "    43:  None, # 'PAT',\n",
    "    51: 'Pass',\n",
    "    52: 'Punt',\n",
    "    53: None, # 'Kickoff',\n",
    "    57: None,\n",
    "    59: 'FG',\n",
    "    60: 'FG',\n",
    "    61:  None, # 'PAT',\n",
    "    62:  None, # 'PAT',\n",
    "    65: None,\n",
    "    66: None,\n",
    "    67: 'Pass',\n",
    "    68: 'Rush',\n",
    "    69: None,\n",
    "    70: None,\n",
    "    74: None,\n",
    "    75: None,\n",
    "    79: None\n",
    "}\n",
    "\n",
    "data_df['playtype'] =  data_df['playtype_id'].map(playtype_mapping)\n",
    "data_df.drop(labels=['playtype_id'], axis=1, inplace=True)\n",
    "data_df.dropna(subset=['playtype'], inplace=True)\n",
    "data_df.drop(labels=['playtype'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature engineering \n",
    "# def map_possession(n):\n",
    "#     if n == 0:\n",
    "#         return 0\n",
    "#     return (n - 1) // 8 + 1 if n > 0 else (n + 1) // 8 - 1\n",
    "\n",
    "# def isFieldGoalEnough(scoreDiff, map_func):\n",
    "#     original_nPossession = map_func(scoreDiff)\n",
    "#     new_nPossession = map_func(scoreDiff + 3)\n",
    "#     return original_nPossession != new_nPossession\n",
    "\n",
    "# data_df['nPossession'] = data_df['scoreDiff'].apply(map_possession)\n",
    "# data_df['fieldGoalEnough'] = data_df['scoreDiff'].apply(lambda x: isFieldGoalEnough(x, map_possession))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.drop(['homeWinPercentage', 'awayWinPercentage', 'tiePercentage'], axis=1).copy()\n",
    "y = data_df[['homeWinPercentage', 'awayWinPercentage', 'tiePercentage']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_num_columns = list(X.select_dtypes(include=\"number\").columns.to_list())\n",
    "X_cat_columns = list(X.select_dtypes(exclude=\"number\").columns.to_list())\n",
    "num_indices = [X.columns.get_loc(col) for col in X_num_columns]\n",
    "cat_indices = [X.columns.get_loc(col) for col in X_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_indices),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_indices)\n",
    "    ])\n",
    "\n",
    "def create_nn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),  # Specifies that input data has 10 features\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),  # Dropout to prevent overfitting\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),  # Dropout to prevent overfitting\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(3, activation='softmax')  # Output layer\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'mse', 'r2_score', 'mae'])\n",
    "    return model\n",
    "\n",
    "keras_model = KerasRegressor(model=create_nn_model, input_dim=preprocessor.fit_transform(X_train).shape[1], epochs=25, verbose=1, batch_size=128)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Preprocessing (scaling + encoding)\n",
    "    ('model', keras_model)           # Neural network model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train, model__validation_data=(preprocessor.transform(X_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# test_season = random.choice(X_test['season'].unique())\n",
    "# test_week = random.choice(X_test['week'].unique())\n",
    "# test_homeAbr = random.choice(X_test.loc[(X_test['season']==test_season)&(X_test['week']==test_week), 'homeAbr'].unique())\n",
    "# print(test_season, test_week, test_homeAbr)\n",
    "# X_game = X_test.loc[(X_test['season']==test_season)&(X_test['week']==test_week)&(X_test['homeAbr']==test_homeAbr)]\n",
    "# y_game = y_test.loc[(X_test['season']==test_season)&(X_test['week']==test_week)&(X_test['homeAbr']==test_homeAbr)]\n",
    "test_season = random.choice([2025])\n",
    "test_week = random.choice([1])\n",
    "for test_homeAbr in X.loc[(X['season']==test_season)&(X['week']==test_week), 'homeAbr'].unique():\n",
    "    print(test_season, test_week, test_homeAbr)\n",
    "    X_game = X.loc[(X['season']==test_season)&(X['week']==test_week)&(X['homeAbr']==test_homeAbr)]\n",
    "    y_game = y.loc[(X['season']==test_season)&(X['week']==test_week)&(X['homeAbr']==test_homeAbr)]\n",
    "\n",
    "    y_game_pred = pd.DataFrame(pipeline.predict(X_game), columns=['homePredicted', 'awayPredicted', 'tiePredicted'])\n",
    "    X_game.reset_index(drop=True, inplace=True)\n",
    "    y_game.reset_index(drop=True, inplace=True)\n",
    "    y_game_pred.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    game_comparison = pd.concat([X_game, y_game, y_game_pred], axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the data\n",
    "    ax.plot(game_comparison['totalTimeLeft'] / 60, game_comparison['homeWinPercentage']*100, label=\"Home Win % (ESPN)\", color=\"navy\", linewidth=2)\n",
    "    ax.plot(game_comparison['totalTimeLeft'] / 60, game_comparison['homePredicted']*100, label=\"Home Win % (neural network)\", color=\"orangered\", linewidth=2)\n",
    "\n",
    "    # Add a horizontal zero-line\n",
    "    ax.axhline(50, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Add vertical dashed lines every 15 minutes\n",
    "    for time in range(0, 3600, 900):  # 900 seconds = 15 minutes\n",
    "        ax.axvline(time / 60, color=\"gray\", linestyle=\"--\", linewidth=0.75, alpha=0.7)\n",
    "\n",
    "    # Set axis labels\n",
    "    #ax.set_xlabel(\"Time Remaining [minutes]\", fontsize=12)\n",
    "    ax.set_ylabel(\"Win Probability [%]\", fontsize=12)\n",
    "\n",
    "    # Set x-axis and y-axis limits\n",
    "    ax.set_xlim(60, 0)  # 3600 seconds = 60 minutes\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # Add a grid for better readability\n",
    "    #ax.grid(visible=True, which=\"both\", color=\"lightgray\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    quarter_labels = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    quarter_positions = [3600 / 60 - 7.5, 2700 / 60 - 7.5, 1800 / 60 - 7.5, 900 / 60 - 7.5]  # Middle of intervals\n",
    "    ax.set_xticks(quarter_positions)\n",
    "    ax.set_xticklabels(quarter_labels, fontsize=12)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc=\"upper left\", fontsize=10, frameon=False)\n",
    "\n",
    "    # Add title\n",
    "    ax.set_title(\"Win Probability vs. Time Remaining\", fontsize=14, pad=15)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('nn_regressor.pkl', 'wb') as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
