{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, Boolean, ForeignKey, DateTime, Time, BigInteger, Text, text, UniqueConstraint, ForeignKeyConstraint\n",
    "from sqlalchemy.types import Integer\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from keys import mysql_password       # import passwords from local file (not pushed to github)\n",
    "\n",
    "sql_engine = create_engine(f\"mysql+pymysql://root:{mysql_password}@localhost:3306\")\n",
    "sql_engine.connect().execute(text(\"CREATE DATABASE IF NOT EXISTS nfl;\"))\n",
    "sql_engine = create_engine(f\"mysql+pymysql://root:{mysql_password}@localhost:3306/nfl\", pool_size=20, max_overflow=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "\n",
    "# Table for the player data (index: player_id -> primary key)\n",
    "players_table = Table(\n",
    "    'players', metadata,\n",
    "    Column('player_id', Integer, primary_key=True),  # Set index as primary key\n",
    "    Column('team_id', Integer, ForeignKey('teams.team_id')),\n",
    "    Column('firstName', String(100)),\n",
    "    Column('lastName', String(100)),\n",
    "    Column('weight', Float),\n",
    "    Column('height', Float),\n",
    "    Column('age', Integer, nullable=True),\n",
    "    Column('link', String(255)),\n",
    "    Column('country', String(100), nullable=True),\n",
    "    Column('picture', String(255), nullable=True),\n",
    "    Column('jersey', Integer, nullable=True),\n",
    "    Column('position_id', Integer, ForeignKey('positions.position_id')),\n",
    "    Column('experience', Integer),\n",
    "    Column('active', Boolean),\n",
    "    Column('status_id', Integer, ForeignKey('playerstatuses.status_id')),\n",
    "    Column('college_id', Integer, ForeignKey('colleges.college_id'))\n",
    ")\n",
    "\n",
    "# Table for the status data (index: status_id -> primary key)\n",
    "playerstatuses_table = Table(\n",
    "    'playerstatuses', metadata,\n",
    "    Column('status_id', Integer, primary_key=True),  # Set index as primary key\n",
    "    Column('name', String(100))\n",
    ")\n",
    "\n",
    "# Table for the team info data (index: team_id -> primary key)\n",
    "teams_table = Table(\n",
    "    'teams', metadata,\n",
    "    Column('team_id', Integer, primary_key=True),  # Set index as primary key\n",
    "    Column('abbreviation', String(10)),\n",
    "    Column('name', String(255)),\n",
    "    Column('location', String(255)),\n",
    "    Column('color', String(50)),\n",
    "    Column('logo', String(255)),\n",
    "    Column('link', String(255))\n",
    ")\n",
    "\n",
    "# Table for the college data (index: college_id -> primary key)\n",
    "colleges_table = Table(\n",
    "    'colleges', metadata,\n",
    "    Column('college_id', Integer, primary_key=True),  # Set index as primary key\n",
    "    Column('name', String(255)),\n",
    "    Column('abbreviation', String(10), nullable=True),\n",
    "    Column('logo', String(255), nullable=True),\n",
    "    Column('mascot', String(255), nullable=True)\n",
    ")\n",
    "\n",
    "# Table for the position data (index: position_id -> primary key)\n",
    "positions_table = Table(\n",
    "    'positions', metadata,\n",
    "    Column('position_id', Integer, primary_key=True),  # Set index as primary key\n",
    "    Column('name', String(100)),\n",
    "    Column('abbreviation', String(10)),\n",
    "    Column('parent', Integer, nullable=True),  # Nullable in case parent position is not specified\n",
    ")\n",
    "\n",
    "games_table = Table(\n",
    "    'games', metadata,\n",
    "    Column('game_id', Integer, primary_key=True),\n",
    "    Column('date', DateTime(timezone=True)),\n",
    "    Column('name', String(255)),\n",
    "    Column('season', Integer),\n",
    "    Column('game_type', String(100)),\n",
    "    Column('week', Integer),\n",
    "    Column('home_team_id', Integer, ForeignKey('teams.team_id')),\n",
    "    Column('home_team_score', Integer),\n",
    "    Column('away_team_id', Integer, ForeignKey('teams.team_id')),\n",
    "    Column('away_team_score', Integer),\n",
    "    Column('standing_home_overall_win', Integer),\n",
    "    Column('standing_home_Home_win', Integer),\n",
    "    Column('standing_home_Road_win', Integer),\n",
    "    Column('standing_home_overall_loss', Integer),\n",
    "    Column('standing_home_Home_loss', Integer),\n",
    "    Column('standing_home_Road_loss', Integer),\n",
    "    Column('standing_away_overall_win', Integer),\n",
    "    Column('standing_away_Home_win', Integer),\n",
    "    Column('standing_away_Road_win', Integer),\n",
    "    Column('standing_away_overall_loss', Integer),\n",
    "    Column('standing_away_Home_loss', Integer),\n",
    "    Column('standing_away_Road_loss', Integer),\n",
    "    Column('link', String(255)),\n",
    "    Column('game_status', String(100)),\n",
    ")\n",
    "\n",
    "playtypes_table = Table(\n",
    "    'playtypes', metadata,\n",
    "    Column('playtype_id', Integer, primary_key=True),  \n",
    "    Column('text', String(255)),  \n",
    "    Column('abbreviation', String(10), nullable=True)\n",
    ")\n",
    "\n",
    "plays_table = Table(\n",
    "    'plays', metadata,\n",
    "    Column('play_id', BigInteger, primary_key=True),  \n",
    "    Column('game_id', Integer, ForeignKey('games.game_id')),  \n",
    "    Column('sequenceNumber', Integer),\n",
    "    Column('homeScore', Integer),\n",
    "    Column('awayScore', Integer),\n",
    "    Column('quarter', Integer),\n",
    "    Column('clock', Time),\n",
    "    Column('offenseAtHome', Boolean),\n",
    "    Column('down', Integer),\n",
    "    Column('distance', Integer),\n",
    "    Column('yardsToEndzone', Integer),\n",
    "    Column('possessionChange', Boolean),\n",
    "    Column('next_down', Integer),\n",
    "    Column('next_distance', Integer),\n",
    "    Column('next_yardsToEndzone', Integer),\n",
    "    Column('playtype_id', Integer, ForeignKey('playtypes.playtype_id')),\n",
    "    Column('description', Text),\n",
    "    UniqueConstraint('game_id', 'sequenceNumber', name='uq_plays_game_sequence')\n",
    ")\n",
    "\n",
    "probabilities_table = Table(\n",
    "    'probabilities', metadata,\n",
    "    Column('proba_id', BigInteger, primary_key=True),  # Unique identifier\n",
    "    Column('game_id', Integer, nullable=False),  # Game identifier\n",
    "    Column('sequenceNumber', Integer, nullable=False),  # Sequence number\n",
    "    Column('homeWinPercentage', Float, nullable=False),  # Probability of home win\n",
    "    Column('awayWinPercentage', Float, nullable=False),  # Probability of away win\n",
    "    Column('tiePercentage', Float, nullable=False),  # Probability of tie\n",
    "    ForeignKeyConstraint(\n",
    "        ['game_id', 'sequenceNumber'],  # Composite FK in probabilities\n",
    "        ['plays.game_id', 'plays.sequenceNumber'],  # Composite key in plays\n",
    "        name='fk_probabilities_plays'\n",
    "    )\n",
    ")\n",
    "\n",
    "news_table = Table(\n",
    "    'news', metadata,\n",
    "    Column('news_id', Integer, primary_key=True),  # Index column as primary key\n",
    "    Column('headline', String(255), nullable=False),\n",
    "    Column('description', String(1000), nullable=False),\n",
    "    Column('published', DateTime(timezone=True), nullable=False),\n",
    "    Column('story', Text, nullable=False)\n",
    ")\n",
    "\n",
    "metadata.create_all(sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_ids(sql_engine, table, id_column):\n",
    "    result = sql_engine.connect().execute(text(f\"SELECT {id_column} FROM {table}\"))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=[id_column])\n",
    "    if df.empty:\n",
    "        return set()  # Return an empty set if no rows are found\n",
    "    return set(df[id_column].tolist())\n",
    "\n",
    "def append_new_rows(dataframe, table, sql_engine, id_column):\n",
    "    existing_ids_set = get_existing_ids(sql_engine, table, id_column)\n",
    "    if not existing_ids_set:  # If there are no existing IDs in the SQL table\n",
    "        dataframe.to_sql(table, con=sql_engine, if_exists='append', index=True, index_label=id_column)\n",
    "    else:\n",
    "        new_rows = dataframe[~dataframe.index.isin(existing_ids_set)]\n",
    "        new_rows.to_sql(table, con=sql_engine, if_exists='append', index=True, index_label=id_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nfl_teams():\n",
    "    url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams\"\n",
    "    response = requests.get(url)\n",
    "    team_data = response.json()\n",
    "\n",
    "    teams = []\n",
    "    for team_id in range(-2,35):\n",
    "        url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams/{team_id}\"\n",
    "        response = requests.get(url)\n",
    "        team_data = response.json()\n",
    "\n",
    "        team = {}\n",
    "        team['team_id'] = team_id\n",
    "        team['abbreviation'] = team_data.get('team', {}).get('abbreviation')\n",
    "        team['name'] = team_data.get('team', {}).get('displayName')\n",
    "        team['location'] = team_data.get('team', {}).get('location')\n",
    "        team['color'] = team_data.get('team', {}).get('color')\n",
    "        team['logo'] = (team_data.get('team', {}).get('logos', [{}])[0]).get('href')\n",
    "        team['link'] = (team_data.get('team', {}).get('links', [{}])[0]).get('href')\n",
    "        teams.append(team)  \n",
    "\n",
    "    teams_df = pd.DataFrame(teams)\n",
    "    teams_df['team_id'] = teams_df['team_id'].astype('Int64')\n",
    "    teams_df.sort_values(by='team_id', inplace=True)\n",
    "    teams_df.set_index('team_id', inplace=True)\n",
    "    return teams_df\n",
    "\n",
    "teams_df = get_nfl_teams()\n",
    "try:\n",
    "    append_new_rows(teams_df, 'teams', sql_engine, 'team_id')\n",
    "except:\n",
    "    append_new_rows(teams_df, 'teams', sql_engine, 'team_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players\n",
    "(+ Status and Colleges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nfl_players(team_ids):\n",
    "    players = []\n",
    "    status_data = {}\n",
    "    colleges = set()\n",
    "\n",
    "    for team_id in team_ids:\n",
    "        #print(\"Currently getting team\",team_id)\n",
    "        url = f\"https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/seasons/2024/teams/{team_id}/athletes?limit=200\"\n",
    "        team_response = requests.get(url)\n",
    "        team_roster = team_response.json()\n",
    "        team_response = requests.get(url)\n",
    "        for i in range(len(team_roster['items'])):   # players per team\n",
    "            player_response = requests.get(team_roster['items'][i]['$ref'])\n",
    "            player_data = player_response.json()\n",
    "            player = {}\n",
    "            player['player_id'] = player_data.get('id', None)\n",
    "            player['team_id'] = team_id  # Assuming team_id is already safely set\n",
    "            player['firstName'] = player_data.get('firstName', None)\n",
    "            player['lastName'] = player_data.get('lastName', None)\n",
    "            player['weight'] = player_data.get('weight', None)\n",
    "            player['height'] = player_data.get('height', None)\n",
    "            player['age'] = player_data.get('age', None)\n",
    "            player['link'] = player_data.get('links', [{}])[0].get('href', None)\n",
    "            player['country'] = player_data.get('birthPlace', {}).get('country', None)\n",
    "            player['picture'] = player_data.get('headshot', {}).get('href', None)\n",
    "            player['jersey'] = player_data.get('jersey', None)\n",
    "            player['position_id'] = player_data.get('position', {}).get('id', None)\n",
    "            player['experience'] = player_data.get('experience', {}).get('years', None)\n",
    "            player['active'] = player_data.get('active', None)\n",
    "            player['status_id'] = player_data.get('status', {}).get('id', None)\n",
    "            player['college_id'] = player_data.get('college', {}).get('$ref', 'unknown').split('/')[-1].split('?')[0]\n",
    "            if player['college_id'] == 'unknown':\n",
    "                player['college_id'] = None\n",
    "            else:\n",
    "                colleges.add(player['college_id'])\n",
    "            \n",
    "            status_data[player['status_id']] = player_data.get('status', {}).get('name', None)\n",
    "            \n",
    "            players.append(player)\n",
    "\n",
    "    players_df = pd.DataFrame(players)\n",
    "    players_df['player_id'] = players_df['player_id'].astype('Int64')\n",
    "    players_df['status_id'] = players_df['status_id'].astype('Int64')\n",
    "    players_df['college_id'] = players_df['college_id'].astype('Int64')\n",
    "    players_df.sort_values(by='player_id', inplace=True)\n",
    "    players_df.set_index('player_id', inplace=True)\n",
    "\n",
    "    status_df = pd.DataFrame(list(status_data.items()), columns=['status_id', 'name'])\n",
    "    status_df['status_id'] = status_df['status_id'].astype('Int64')\n",
    "    status_df.sort_values(by='status_id', inplace=True)\n",
    "    status_df.set_index('status_id', inplace=True)\n",
    "\n",
    "    return players_df, status_df, colleges\n",
    "\n",
    "players_df, status_df, college_ids = get_nfl_players(teams_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colleges(college_ids):\n",
    "    colleges = []\n",
    "    for college_id in list(college_ids):\n",
    "        url = f\"http://sports.core.api.espn.com/v2/colleges/{college_id}?lang=en&region=us\"\n",
    "        college_response = requests.get(url)\n",
    "        college_data = college_response.json()\n",
    "        college = {}\n",
    "        college['college_id'] = college_id\n",
    "        college['name'] = college_data.get('name', None)\n",
    "        college['abbreviation'] = college_data.get('abbrev', None)\n",
    "        college['logo'] = college_data.get('logos', [{}])[0].get('href', None)\n",
    "        college['mascot'] = college_data.get('mascot', None)\n",
    "        colleges.append(college)\n",
    "    colleges_df = pd.DataFrame(colleges)\n",
    "    colleges_df['college_id'] = colleges_df['college_id'].astype('Int64')\n",
    "    colleges_df.set_index('college_id', inplace=True)\n",
    "    return colleges_df\n",
    "\n",
    "colleges_df = get_colleges(college_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions(position_ids):\n",
    "    positions = []\n",
    "    for position_id in position_ids:\n",
    "        url = f\"http://sports.core.api.espn.com/v2/sports/football/leagues/nfl/positions/{position_id}?lang=en&region=us\"\n",
    "        position_response = requests.get(url)\n",
    "        position_data = position_response.json()\n",
    "        position = {}\n",
    "        position['position_id'] = position_id\n",
    "        position['name'] = position_data.get('name', None)\n",
    "        position['abbreviation'] = position_data.get('abbreviation', None)\n",
    "        position['parent'] = position_data.get('parent', {}).get('$ref', 'unknown').split('/')[-1].split('?')[0]\n",
    "        if position['parent'] == 'unknown':\n",
    "            position['parent'] = None\n",
    "        positions.append(position)\n",
    "\n",
    "    positions_df = pd.DataFrame(positions)\n",
    "    positions_df['position_id'] = positions_df['position_id'].astype('Int64')\n",
    "    positions_df['parent'] = positions_df['parent'].astype('Int64')\n",
    "    positions_df.set_index('position_id', inplace=True)\n",
    "    positions_df.drop_duplicates(inplace=True)\n",
    "    return positions_df\n",
    "\n",
    "position_ids = set()\n",
    "for i in players_df['position_id'].values:\n",
    "    position_ids.add(i)\n",
    "positions_df = get_positions(position_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_new_rows(positions_df, 'positions', sql_engine, 'position_id')\n",
    "append_new_rows(colleges_df, 'colleges', sql_engine, 'college_id')\n",
    "append_new_rows(status_df, 'playerstatuses', sql_engine, 'status_id')\n",
    "append_new_rows(players_df, 'players', sql_engine, 'player_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2009\n",
      "Year: 2010\n",
      "Year: 2011\n",
      "Year: 2012\n",
      "Year: 2013\n",
      "Year: 2014\n",
      "Year: 2015\n",
      "Year: 2016\n",
      "Year: 2017\n",
      "Year: 2018\n",
      "Year: 2019\n",
      "Year: 2020\n",
      "Year: 2021\n"
     ]
    }
   ],
   "source": [
    "def get_games(years):\n",
    "    games = []\n",
    "\n",
    "    weeks = {2: list(range(1,19)),\n",
    "            3: [1,2,3,4,5]}\n",
    "\n",
    "    years_in_db = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT season FROM games\")).fetchall()]\n",
    "\n",
    "    for year in list(set(years) - set(years_in_db)):\n",
    "\n",
    "        for seasontype in [2,3]:\n",
    "            #print('SeasonType:', seasontype, end=' Weeks: ')\n",
    "            for week in weeks[seasontype]:\n",
    "                #print(week, end=' ')\n",
    "                url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?dates={year}&seasontype={seasontype}&week={week}\"\n",
    "                games_response = requests.get(url)\n",
    "                games_data = games_response.json()\n",
    "\n",
    "                for game_ind in range(len(games_data['events'])):\n",
    "                    game_data = games_data['events'][game_ind]\n",
    "                    game = {}\n",
    "                    game['game_id'] = game_data.get('id', None)\n",
    "                    game['date'] = game_data.get('date', None)\n",
    "                    game['name'] = game_data.get('name', None)\n",
    "                    game['season'] = game_data.get('season', {}).get('year', None)\n",
    "                    game['game_type'] = game_data.get('season', {}).get('slug', None)\n",
    "                    game['week'] = game_data.get('week', {}).get('number', None)\n",
    "                    if game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('homeAway', None) == \"home\":\n",
    "                        game['home_team_id'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('team', {}).get('id', None)\n",
    "                        game['home_team_score'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('score', None)\n",
    "                        for i in range(3):\n",
    "                            standing = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('name', '')\n",
    "                            if not standing=='':\n",
    "                                game['standing_home_'+standing+'_win'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('summary', [None])[0]\n",
    "                                game['standing_home_'+standing+'_loss'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('summary', [None])[-1]\n",
    "\n",
    "                        game['away_team_id'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('team', {}).get('id', None)\n",
    "                        game['away_team_score'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('score', None)\n",
    "                        for i in range(3):\n",
    "                            standing = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('name', '')\n",
    "                            if not standing=='':\n",
    "                                game['standing_away_'+standing+'_win'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('summary', [None])[0]\n",
    "                                game['standing_away_'+standing+'_loss'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('summary', [None])[-1]\n",
    "\n",
    "                    else:\n",
    "                        game['home_team_id'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('team', {}).get('id', None)\n",
    "                        game['home_team_abr'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('team', {}).get('abbreviation', None)\n",
    "                        game['home_team_score'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('score', None)\n",
    "                        for i in range(3):\n",
    "                            standing = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('name', '')\n",
    "                            if not standing=='':\n",
    "                                game['standing_home_'+standing+'_win'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('summary', [None])[0]\n",
    "                                game['standing_home_'+standing+'_loss'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[1].get('records', [{},{},{}])[i].get('summary', [None])[-1]\n",
    "                            \n",
    "                        game['away_team_id'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('team', {}).get('id', None)\n",
    "                        game['away_team_abr'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('team', {}).get('abbreviation', None)\n",
    "                        game['away_team_score'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('score', None)\n",
    "                        for i in range(3):\n",
    "                            standing = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('name', '')\n",
    "                            if not standing=='':\n",
    "                                game['standing_away_'+standing+'_win'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('summary', [None])[0]\n",
    "                                game['standing_away_'+standing+'_loss'] = game_data.get('competitions', [{}])[0].get('competitors', [{},{}])[0].get('records', [{},{},{}])[i].get('summary', [None])[-1]\n",
    "                    game['link'] = game_data.get('links', [{}])[0].get('href', None)\n",
    "                    game['game_status'] = game_data.get('status', {}).get('type', {}).get('id', None)\n",
    "                    games.append(game)\n",
    "            #print('')\n",
    "    games_df = pd.DataFrame(games)\n",
    "    games_df['game_id'] = games_df['game_id'].astype('Int64')\n",
    "    games_df['home_team_id'] = games_df['home_team_id'].astype('Int64')\n",
    "    games_df['home_team_score'] = games_df['home_team_score'].astype('Int64')\n",
    "    games_df['away_team_id'] = games_df['away_team_id'].astype('Int64')\n",
    "    games_df['away_team_score'] = games_df['away_team_score'].astype('Int64')\n",
    "    games_df['date'] = pd.to_datetime(games_df['date'])\n",
    "    games_df.set_index('game_id', inplace=True)\n",
    "\n",
    "    return games_df\n",
    "\n",
    "years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009]\n",
    "games_df = get_games(years)\n",
    "\n",
    "append_new_rows(games_df, 'games', sql_engine, 'game_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 games still missing - Succesfully appended some new rows\n",
      "177 games still missing - Succesfully appended some new rows\n",
      "165 games still missing - Succesfully appended some new rows\n"
     ]
    }
   ],
   "source": [
    "def get_plays(game_ids):\n",
    "    plays = []\n",
    "    playtypes = []\n",
    "\n",
    "    #random.shuffle(game_ids)\n",
    "\n",
    "    #games_in_db = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM plays\")).fetchall()]\n",
    "\n",
    "    for game_id in game_ids: #list(set(game_ids) - set(games_in_db)):\n",
    "\n",
    "        url = f\"https://cdn.espn.com/core/nfl/playbyplay?xhr=1&gameId={game_id}\"\n",
    "\n",
    "        try:\n",
    "            game_response = requests.get(url)\n",
    "            if game_response.status_code == 200:\n",
    "                try:\n",
    "                    game_data = game_response.json()\n",
    "\n",
    "                    drives_data = game_data.get('gamepackageJSON', {}).get('drives',{}).get('previous', [])\n",
    "\n",
    "                    game_from_sql = sql_engine.connect().execute(text(f\"SELECT * FROM games where game_id = {game_id}\"))\n",
    "                    game_df = pd.DataFrame(game_from_sql.fetchall())\n",
    "\n",
    "                    for drive_i in range(len(drives_data)):\n",
    "                        drive_data = drives_data[drive_i]\n",
    "                        plays_data = drive_data.get('plays',[])\n",
    "                        for sequence_i in range(len(plays_data)):\n",
    "                            play_data = plays_data[sequence_i]\n",
    "\n",
    "                            play = {}\n",
    "                            play['play_id'] = play_data.get('id', None)\n",
    "                            play['game_id'] = game_id\n",
    "                            play['sequenceNumber'] = play_data.get('sequenceNumber', None)\n",
    "                            play['homeScore'] = play_data.get('homeScore', None)\n",
    "                            play['awayScore'] = play_data.get('awayScore', None)\n",
    "                            play['quarter'] = play_data.get('period', {}).get('number', None)\n",
    "                            play['clock'] = play_data.get('clock', {}).get('displayValue', None)\n",
    "\n",
    "                            offense_team_id = play_data.get('start', {}).get('team', {}).get('id', None)\n",
    "\n",
    "                            if offense_team_id == None:\n",
    "                                play['offenseAtHome'] = None\n",
    "                            elif int(offense_team_id) == game_df['home_team_id'].values[0]:\n",
    "                                play['offenseAtHome'] = True\n",
    "                            else:\n",
    "                                play['offenseAtHome'] = False\n",
    "\n",
    "                            play['down'] = play_data.get('start', {}).get('down', None)\n",
    "                            play['distance'] = play_data.get('start', {}).get('distance', None)\n",
    "                            play['yardsToEndzone'] = play_data.get('start', {}).get('yardsToEndzone', None)\n",
    "\n",
    "                            next_team_id = play_data.get('end', {}).get('team', {}).get('id', None)\n",
    "\n",
    "                            if next_team_id == None:\n",
    "                                play['possessionChange'] = None\n",
    "                            elif next_team_id== offense_team_id:\n",
    "                                play['possessionChange'] = False\n",
    "                            else:\n",
    "                                play['possessionChange'] = False\n",
    "\n",
    "                            play['next_down'] = play_data.get('end', {}).get('down', None)\n",
    "                            play['next_distance'] = play_data.get('end', {}).get('distance', None)\n",
    "                            play['next_yardsToEndzone'] = play_data.get('end', {}).get('yardsToEndzone', None)\n",
    "\n",
    "                            play['playtype_id'] = play_data.get('type', {}).get('id', None)\n",
    "                            play['description'] = play_data.get('text', None)\n",
    "\n",
    "                            plays.append(play)\n",
    "                            playtypes.append(play_data.get('type', {}))\n",
    "                except Exception as e:\n",
    "                    print(\"JSON error for game_id\", game_id, e)\n",
    "            else:\n",
    "                print(\"No 200 response for game_id\", game_id)\n",
    "        except Exception as e:\n",
    "            print(\"No response from Server for game_id\", game_id)\n",
    "\n",
    "    if len(plays)>0:\n",
    "        playtypes_df = pd.DataFrame(playtypes)\n",
    "        playtypes_df.drop_duplicates(inplace=True)\n",
    "        playtypes_df['id'] = playtypes_df['id'].astype('Int64')\n",
    "        playtypes_df.sort_values(by='id', inplace=True)\n",
    "        playtypes_df.rename(columns={'id': 'playtype_id'}, inplace=True)\n",
    "        playtypes_df.set_index('playtype_id', inplace=True)\n",
    "\n",
    "        plays_df = pd.DataFrame(plays)\n",
    "        plays_df['play_id'] = plays_df['play_id'].astype('Int64')\n",
    "        plays_df['clock'] = '00:' + plays_df['clock']\n",
    "        plays_df['playtype_id'] = plays_df['playtype_id'].astype('Int64')\n",
    "        plays_df['sequenceNumber'] = plays_df['sequenceNumber'].astype('Int64')\n",
    "        plays_df.set_index('play_id', inplace=True)\n",
    "\n",
    "        return plays_df, playtypes_df\n",
    "    else:\n",
    "        return [], []\n",
    "\n",
    "ids_in_games = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM games WHERE season in (2023, 2024)\")).fetchall()]\n",
    "ids_in_plays = list(get_existing_ids(sql_engine, 'plays', 'game_id'))\n",
    "\n",
    "missing_games = list(set(ids_in_games) - set(ids_in_plays))\n",
    "\n",
    "while len(missing_games)>0:\n",
    "\n",
    "    print(len(missing_games), \"games still missing\", end = ' ')\n",
    "    #random.shuffle(missing_games)\n",
    "\n",
    "    plays_df, playtypes_df = get_plays(missing_games[0:100])\n",
    "\n",
    "    if len(plays_df)>0:\n",
    "        \n",
    "        plays_df.drop_duplicates(subset=['game_id', 'sequenceNumber'], keep='last', inplace=True)\n",
    "        append_new_rows(playtypes_df, 'playtypes', sql_engine, 'playtype_id')\n",
    "        append_new_rows(plays_df, 'plays', sql_engine, 'play_id')\n",
    "        print('- Succesfully appended some new rows')\n",
    "    else:\n",
    "        print(\"No new data\")\n",
    "\n",
    "    ids_in_games = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM games WHERE season in (2023, 2024)\")).fetchall()]\n",
    "    ids_in_plays = list(get_existing_ids(sql_engine, 'plays', 'game_id'))\n",
    "\n",
    "    missing_games = list(set(ids_in_games) - set(ids_in_plays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_probabilities(dataframe, table, sql_engine, id_column):\n",
    "    existing_ids_set = get_existing_ids(sql_engine, table, id_column)\n",
    "    if not existing_ids_set:  # If there are no existing IDs in the SQL table\n",
    "        for index, row in dataframe.iterrows():\n",
    "            try:\n",
    "                row.to_frame().T.to_sql('probabilities', con=sql_engine, if_exists='append', index=True, index_label=id_column)\n",
    "            except:\n",
    "                print(row.values)\n",
    "    else:\n",
    "        new_rows = dataframe[~dataframe.index.isin(existing_ids_set)]\n",
    "        for index, row in new_rows.iterrows():\n",
    "            try:\n",
    "                row.to_frame().T.to_sql('probabilities', con=sql_engine, if_exists='append', index=True, index_label=id_column)\n",
    "            except Exception as e:\n",
    "                #if not row.values[1]==100:\n",
    "                #    print(row.values)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended some new probabilities.\n",
      "Appended some new probabilities.\n",
      "Appended some new probabilities.\n",
      "Appended some new probabilities.\n",
      "Appended some new probabilities.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_games)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(missing_games)\n\u001b[0;32m---> 39\u001b[0m     percentages_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissing_games\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     append_new_probabilities(percentages_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m'\u001b[39m, sql_engine, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproba_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAppended some new probabilities.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[115], line 7\u001b[0m, in \u001b[0;36mget_probabilities\u001b[0;34m(game_ids)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/competitions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/probabilities?limit=3000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      9\u001b[0m     pages \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpageCount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    695\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-notebooks/nfl/.venv/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_probabilities(game_ids):\n",
    "    percentages = []\n",
    "    #games_in_db = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM probabilities\")).fetchall()]\n",
    "    for game_id in game_ids: #  list(set(game_ids) - set(games_in_db)):\n",
    "        try:\n",
    "            url = f\"https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/{game_id}/competitions/{game_id}/probabilities?limit=3000\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            pages = data.get('pageCount', 0)\n",
    "            for page in range(1,pages+1):\n",
    "                url = f\"https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/{game_id}/competitions/{game_id}/probabilities?limit=3000&page={page}\"\n",
    "                response = requests.get(url)\n",
    "                data = response.json()\n",
    "                for item in data['items']:\n",
    "                    percentage_data = {}\n",
    "                    percentage_data['proba_id'] = int(str(game_id)+str(item.get('sequenceNumber', None)))\n",
    "                    percentage_data['game_id'] = game_id\n",
    "                    percentage_data['sequenceNumber'] = item.get('sequenceNumber', None)\n",
    "                    percentage_data['homeWinPercentage'] = item.get('homeWinPercentage', None)\n",
    "                    percentage_data['awayWinPercentage'] = item.get('awayWinPercentage', None)\n",
    "                    percentage_data['tiePercentage'] = item.get('tiePercentage', None)\n",
    "                    percentages.append(percentage_data)\n",
    "        except Exception as e:\n",
    "            print(game_id, e)\n",
    "    percentages_df = pd.DataFrame(percentages)\n",
    "    percentages_df['sequenceNumber'] = percentages_df['sequenceNumber'].astype('Int64')\n",
    "    percentages_df.set_index('proba_id', inplace=True)\n",
    "    return percentages_df\n",
    "\n",
    "games_with_plays = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM plays p LEFT JOIN games g ON p.game_id=g.game_id WHERE g.season IN (2023, 2024) \")).fetchall()]\n",
    "games_in_proba = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM probabilities\")).fetchall()]\n",
    "\n",
    "missing_games = list(set(games_with_plays) - set(games_in_proba))\n",
    "\n",
    "while len(missing_games)>0:\n",
    "    print(len(missing_games), \"games still missing\", end = ' ')\n",
    "    \n",
    "    #random.shuffle(missing_games)\n",
    "\n",
    "    percentages_df = get_probabilities(missing_games[0:100])\n",
    "    append_new_probabilities(percentages_df, 'probabilities', sql_engine, 'proba_id')\n",
    "    print('Appended some new probabilities.')\n",
    "\n",
    "    games_with_plays = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM plays p LEFT JOIN games g ON p.game_id=g.game_id WHERE g.season IN (2023, 2024) \")).fetchall()]\n",
    "    games_in_proba = [i[0] for i in sql_engine.connect().execute(text(f\"SELECT DISTINCT game_id FROM probabilities\")).fetchall()]\n",
    "\n",
    "    missing_games = list(set(games_with_plays) - set(games_in_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving news from 73 places.\n"
     ]
    }
   ],
   "source": [
    "def get_news(url1, url2, url3, team_ids):\n",
    "\n",
    "    existing_news = get_existing_ids(sql_engine, \"news\", \"news_id\")\n",
    "\n",
    "    news = []\n",
    "    article_links = set()\n",
    "\n",
    "    news_response = requests.get(url1)\n",
    "    news_data = news_response.json()\n",
    "    articles_data = news_data.get('articles', [])\n",
    "    for article_i in articles_data:\n",
    "        article_link = article_i.get('links', {}).get('api', {}).get('news', {}).get('href', '')\n",
    "        article_links.add(article_link)\n",
    "        article_link = article_i.get('links', {}).get('api', {}).get('self', {}).get('href', '')\n",
    "        article_links.add(article_link)\n",
    "\n",
    "    article_links.add(url2)\n",
    "\n",
    "    for team_id in team_ids:\n",
    "        news_response = requests.get(url3+str(team_id))\n",
    "        news_data = news_response.json()\n",
    "        articles_data = news_data.get('articles', [])\n",
    "        for article_i in articles_data:\n",
    "            article_link = article_i.get('links', {}).get('api', {}).get('news', {}).get('href', '')\n",
    "            article_links.add(article_link)\n",
    "            article_link = article_i.get('links', {}).get('api', {}).get('self', {}).get('href', '')\n",
    "            article_links.add(article_link)\n",
    "\n",
    "    cleaned_links = []\n",
    "    for i in article_links:\n",
    "        if ('sports/news' in i):\n",
    "            cleaned_links.append(i)\n",
    "\n",
    "    print(f\"Retrieving news from {len(cleaned_links)} places.\")\n",
    "    for article_link in cleaned_links:\n",
    "        article_response = requests.get(article_link)\n",
    "        article_data = article_response.json()\n",
    "        headlines_data = article_data.get('headlines', [])\n",
    "        for headline_i in headlines_data:\n",
    "            headline_id = headline_i.get('id', None)\n",
    "            if ( (not headline_id == None)and(not headline_id in existing_news) ):\n",
    "                new_news = {}\n",
    "                new_news['news_id'] = headline_id\n",
    "                new_news['headline'] = headline_i.get('headline', None)\n",
    "                new_news['description'] = headline_i.get('description', None)\n",
    "                new_news['published'] = headline_i.get('published', None)\n",
    "                story = headline_i.get('story', None)\n",
    "                story_soup = BeautifulSoup(story, 'html.parser')\n",
    "                story_plain = story_soup.get_text(separator=' ', strip=True)\n",
    "                new_news['story'] = story_plain\n",
    "                news.append(new_news)\n",
    "    if len(news)>0:\n",
    "        news_df = pd.DataFrame(news)\n",
    "        news_df['news_id'] = news_df['news_id'].astype('Int64')\n",
    "        news_df.set_index('news_id', inplace=True)\n",
    "        news_df['published'] = pd.to_datetime(news_df['published'])\n",
    "        news_df = news_df.loc[~news_df.index.duplicated()]\n",
    "        return news_df\n",
    "    else:\n",
    "        print(\"No new news yet.\")\n",
    "\n",
    "news_df = get_news(\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/news?limit=150\", \"https://now.core.api.espn.com/v1/sports/news?limit=1000&sport=football\", \"https://site.api.espn.com/apis/site/v2/sports/football/nfl/news?team=\", range(1,35))\n",
    "\n",
    "append_new_rows(news_df, 'news', sql_engine, 'news_id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
